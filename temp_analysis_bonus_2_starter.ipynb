{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflect Tables into SQLALchemy ORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create engine to hawaii.sqlite\n",
    "engine = create_engine(\"sqlite:///hawaii.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reflect an existing database into a new model\n",
    "Base = automap_base()\n",
    "\n",
    "# reflect the tables\n",
    "Base.prepare(engine, reflect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all of the classes that automap found\n",
    "Base.classes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save references to each table\n",
    "Measurement = Base.classes.measurement\n",
    "Station = Base.classes.station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our session (link) from Python to the DB\n",
    "session = Session(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge Assignment: Temperature Analysis II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function called `calc_temps` will accept start date and end date in the format '%Y-%m-%d' \n",
    "# and return the minimum, maximum, and average temperatures for that range of dates\n",
    "def calc_temps(start_date, end_date):\n",
    "    \"\"\"TMIN, TAVG, and TMAX for a list of dates.\n",
    "    \n",
    "    Args:\n",
    "        start_date (string): A date string in the format %Y-%m-%d\n",
    "        end_date (string): A date string in the format %Y-%m-%d\n",
    "        \n",
    "    Returns:\n",
    "        TMIN, TAVE, and TMAX\n",
    "    \"\"\"\n",
    "    \n",
    "    return session.query(func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)).\\\n",
    "        filter(Measurement.date >= start_date).filter(Measurement.date <= end_date).all()\n",
    "\n",
    "# For example\n",
    "print(calc_temps('2012-02-28', '2012-03-05'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function `calc_temps` to calculate the tmin, tavg, and tmax \n",
    "# for a year in the data set\n",
    "startdate = '2016-02-28'\n",
    "enddate = '2016-03-05'\n",
    "tempresult = calc_temps(startdate,enddate)[0]\n",
    "tempresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results from your previous query as a bar chart. \n",
    "# Use \"Trip Avg Temp\" as your Title\n",
    "# Use the average temperature for the y value\n",
    "# Use the peak-to-peak (tmax-tmin) value as the y error bar (yerr)\n",
    "x_pos = [0]\n",
    "y_pos = [tempresult[1]]\n",
    "error = [(tempresult[2] - tempresult[0])]\n",
    "\n",
    "w = 3\n",
    "h = 5\n",
    "d = 70\n",
    "plt.figure(figsize=(w, h), dpi=d)\n",
    "plt.bar(x_pos,y_pos,color='purple', yerr=error)\n",
    "plt.xlim(-0.75,0.75)\n",
    "plt.title(\"Trip Avg Temp\")\n",
    "plt.ylabel(\"Temp (F)\")\n",
    "plt.ylim(0, 100)\n",
    "plt.tick_params(axis='x',which='both',bottom=False,top=False,labelbottom=False)\n",
    "plt.grid(which='major', axis='x', linestyle='')\n",
    "plt.grid(which='major', axis='y', linestyle='-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily Rainfall Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total amount of rainfall per weather station for your trip dates using the previous year's matching dates.\n",
    "# Sort this in descending order by precipitation amount and list the station, name, latitude, longitude, and elevation\n",
    "\n",
    "# test= [('USC00516128', 'MANOA LYON ARBO 785.2, HI US', 21.3331, -157.8025, 152.4, 0.31), ('USC00519281', 'WAIHEE 837.5, HI US', 21.45167, -157.84888999999998, 32.9, 0.25), ('USC00518838', 'UPPER WAHIAWA 874.3, HI US', 21.4992, -158.0111, 306.6, 0.1), ('USC00513117', 'KANEOHE 838.1, HI US', 21.4234, -157.8015, 14.6, 0.060000000000000005), ('USC00511918', 'HONOLULU OBSERVATORY 702.2, HI US', 21.3152, -157.9992, 0.9, 0.0), ('USC00514830', 'KUALOA RANCH HEADQUARTERS 886.9, HI US', 21.5213, -157.8374, 7.0, 0.0), ('USC00517948', 'PEARL CITY, HI US', 21.3934, -157.9751, 11.9, 0.0), ('USC00519397', 'WAIKIKI 717.2, HI US', 21.2716, -157.8168, 3.0, 0.0), ('USC00519523', 'WAIMANALO EXPERIMENTAL FARM, HI US', 21.33556, -157.71139, 19.5, 0.0)]\n",
    "# test = pd.DataFrame(test, columns=['Station','Name','Latitude','Longitude','Elevation','Prcp'])\n",
    "# test\n",
    "\n",
    "startdate = '2016-01-01'\n",
    "enddate = '2016-01-07'\n",
    "\n",
    "sel = [Measurement.station,func.sum(Measurement.prcp)]\n",
    "queryresult = session.query(*sel).\\\n",
    "    group_by(Measurement.station).\\\n",
    "    filter(Measurement.date >= startdate).\\\n",
    "    filter(Measurement.date <= enddate).all()\n",
    "#     order_by(func.sum(Measurement.prcp).desc()).all()\n",
    "stations_prec = pd.DataFrame(queryresult,columns=['Station','PrcpSum'])\n",
    "\n",
    "sel = [Station.station,Station.name,Station.latitude,Station.longitude,Station.elevation]\n",
    "queryresult = session.query(*sel).all()\n",
    "stations_desc = pd.DataFrame(queryresult, columns=['Station','Name','Latitude','Longitude','Elevation'])\n",
    "\n",
    "stations = pd.merge(stations_desc,stations_prec, on=\"Station\", how=\"left\")\n",
    "stations = stations.sort_values(\"PrcpSum\",ascending=False)\n",
    "stations = stations.fillna(value = {'PrcpSum':0})\n",
    "stations = stations.reset_index(drop=True)\n",
    "stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily Temperature Normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a query that will calculate the daily normals \n",
    "# (i.e. the averages for tmin, tmax, and tavg for all historic data matching a specific month and day)\n",
    "def daily_normals(date):\n",
    "    sel = [func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)]\n",
    "    return session.query(*sel).filter(func.strftime(\"%m-%d\", Measurement.date) == date).all()\n",
    "    \n",
    "daily_normals(\"01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the daily normals for your trip\n",
    "# push each tuple of calculations into a list called `normals`\n",
    "\n",
    "# Set the start and end date of the trip\n",
    "\n",
    "startdate = '2018-01-01'\n",
    "enddate = '2018-01-07'\n",
    "\n",
    "# Use the start and end date to create a range of dates\n",
    "# Stip off the year and save a list of %m-%d strings\n",
    "# Loop through the list of %m-%d strings and calculate the normals for each date\n",
    "\n",
    "dtobj = dt.datetime.strptime(startdate, '%Y-%m-%d')\n",
    "enddtobj = dt.datetime.strptime(enddate, '%Y-%m-%d')\n",
    "\n",
    "tripdates = []\n",
    "normals =[]\n",
    "while (dtobj <= enddtobj):\n",
    "    tripdates.append(dtobj)\n",
    "    datestr = dt.datetime.strftime(dtobj,'%m-%d')\n",
    "    normals.append(list(np.ravel(daily_normals(datestr))))\n",
    "    dtobj = dtobj + dt.timedelta(days = 1)\n",
    "\n",
    "normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previous query results into a Pandas DataFrame and add the `trip_dates` range as the `date` index\n",
    "tripdateinfo_df = pd.DataFrame(normals, columns=['tmin','tavg','tmax'])\n",
    "tripdateinfo_df['Date'] = tripdates\n",
    "tripdateinfo_df = tripdateinfo_df.set_index(\"Date\")\n",
    "tripdateinfo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the daily normals as an area plot with `stacked=False`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
